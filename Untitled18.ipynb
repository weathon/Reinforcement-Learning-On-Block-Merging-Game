{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled18.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOt7ieAZbwlRNW7n09u9PhC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weathon/Reinforcement-Learning-On-Block-Merging-Game/blob/master/Untitled18.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QdgqXeJdW4dF"
      },
      "outputs": [],
      "source": [
        "# award = score*20 - steps*0.1 + merge*2, f died, -100\n",
        "# https://deeplizard.com/learn/video/xVkPh9E9GfE\n",
        "import numpy as np\n",
        "import random\n",
        "import game\n",
        "import copy\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import os\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import PIL\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Input(37),\n",
        "  tf.keras.layers.Dense(60),\n",
        "  tf.keras.layers.Dense(120),\n",
        "  tf.keras.layers.Dense(120),\n",
        "  tf.keras.layers.Dense(60),\n",
        "  tf.keras.layers.Dense(30),\n",
        "  tf.keras.layers.Dense(6,activation=\"softmax\"),\n",
        "])\n",
        "model.summary()\n",
        "model.compile()\n",
        "\n",
        "class memoryCell:\n",
        "    def __init__(self, field, action, num, reward):\n",
        "        field = field\n",
        "        # nextState = ns\n",
        "        action = action\n",
        "        num = num\n",
        "        reward = reward\n",
        "\n",
        "memory = []\n",
        "epsilon = 1\n",
        "\n",
        "target = copy.deepcopy(model)\n",
        "for episode in range(100):\n",
        "    game.init()\n",
        "    for step in range(10000000):\n",
        "        next_number = random.choice(game.choices)\n",
        "        if random.random()<=epsilon:\n",
        "            # random action\n",
        "            action = random.choice([0,1,2,3,4,5])\n",
        "        else:\n",
        "            action = model.predict(game.field, next_number)\n",
        "        \n",
        "        old_score = np.max(game.field)\n",
        "        old_field = copy.copy(game.field)\n",
        "        gameOver = game.push_block(action, next_number)\n",
        "        if gameOver:\n",
        "            reward = -100\n",
        "        else:\n",
        "            game.check_merging()\n",
        "            new_score = np.max(game.field)\n",
        "            if not new_score in game.choices:\n",
        "                game.choices.append(int(new_score/2))\n",
        "            reward = new_score/old_score * 20\n",
        "\n",
        "        # if len(memory)<10:\n",
        "        #     memory.append(memoryCell(field, action, num, reward))\n",
        "        # else:\n",
        "        #     memory[random.randint(10)] = memoryCell(field, action, num, reward)\n",
        "        \n",
        "        current = model(np.append(np.ndarray.flatten(old_field),next_number).reshape(1,-1))\n",
        "        next = target(np.append(np.ndarray.flatten(game.field),random.choice(game.choices)).reshape(1,-1))\n",
        "        nextState = game.field\n",
        "        loss = np.sum(((reward + np.max(next)) - current)**2)\n",
        "        # model.train(loss)\n",
        "        # no need for isolation?\n",
        "\n",
        "        if step%50 == 0:\n",
        "            target = copy.deepcopy(model)\n",
        "\n",
        "        if gameOver:\n",
        "            break"
      ]
    }
  ]
}